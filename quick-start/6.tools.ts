import './lib/loadEnv';
import { Annotation, END, StateGraph } from '@langchain/langgraph';
import { AIMessage, BaseMessage, HumanMessage } from '@langchain/core/messages';
import { ChatOpenAI } from '@langchain/openai';
import { tool } from "@langchain/core/tools";
import { ToolNode } from '@langchain/langgraph/prebuilt';
import z from 'zod';


// ä¸€ã€å·¥å…·å®šä¹‰

/**
 * å¤©æ°”æŸ¥è¯¢å·¥å…·
*/

const getWeather = tool(
    async (input) => {
        return `æœªæ¥ä¸‰å¤©${input.city}çš„å¤©æ°”æ˜¯ï¼š\nä»Šå¤©ï¼šæ™´ï¼Œ25åº¦\næ˜å¤©ï¼šå¤šäº‘ï¼Œ22åº¦\nåå¤©ï¼šå°é›¨ï¼Œ20åº¦`;
    },
    {
        name: 'getWeather',
        description: 'è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ï¼Œè¾“å…¥æ ¼å¼ä¸ºï¼šåŸå¸‚ï¼Œå¦‚ï¼šåŒ—äº¬',
        schema: z.object({
            city: z.string().describe('åŸå¸‚åç§°ï¼Œå¦‚åŒ—äº¬ã€ä¸Šæµ·ã€å¹¿å·ç­‰'),
        })
    }
)

/**
 * æ•°å­¦è®¡ç®—å·¥å…·
*/

const calculate = tool(
    async (input) => {
        const { expression } = input;
        try {
            const result = eval(expression)
            return `è®¡ç®—ç»“æœï¼š${expression} = ${result}`;
        } catch {
            return `æ— æ³•è®¡ç®—è¡¨è¾¾å¼ï¼š${expression}`;
        }
    },
    {
        name: 'calculate',
        description: 'è®¡ç®—æ•°å­¦è¡¨è¾¾å¼ï¼Œå¦‚ï¼š1+2*3',
        schema: z.object({
            expression: z.string().describe('æ•°å­¦è¡¨è¾¾å¼ï¼Œå¦‚ 1+2*3'),
        })
    }
)

// å·¥å…·åˆ—è¡¨
const tools = [getWeather, calculate]

// äºŒã€LLM å®ä¾‹åŒ–

const llm = new ChatOpenAI({
    model: 'qwen3-max',
})

// ä¸‰ã€çŠ¶æ€å®šä¹‰
const StateAnnotation = Annotation.Root({
    messages: Annotation<BaseMessage[]>({
        reducer: (oldState, newState) => {
            return [...oldState, ...newState]
        },
        default: () => []
    })
})

// å››ã€èŠ‚ç‚¹å‡½æ•°å®šä¹‰
const toolNode = new ToolNode(tools)


/**
 * LLM èŠ‚ç‚¹
*/

const llmNode = async (state: typeof StateAnnotation.State) => {
    const llmWithTools = llm.bindTools(tools)
    const response = await llmWithTools.invoke(state.messages)
    return {
        messages: [response]
    }

}



/**
 * æ¡ä»¶è·¯ç”±å‡½æ•°
*/

const shouldContinue = (state: typeof StateAnnotation.State) => {
    const lastMessage = state.messages[state.messages.length - 1] as AIMessage;

    if (lastMessage.tool_calls && lastMessage.tool_calls.length > 0) {
        return 'tools'
    } else {
        return END;
    }
}



// äº”ã€æ„é€ å¹¶ç¼–è¯‘å›¾

export const toolsGraph = new StateGraph(StateAnnotation)
   .addNode('llmNode', llmNode)
   .addNode('toolNode', toolNode)
   .addEdge('__start__', 'llmNode')
   .addConditionalEdges('llmNode', shouldContinue, {
        'tools': 'toolNode',
        [END]: '__end__'
   })
   .addEdge('toolNode', 'llmNode')
   .compile()


// å…­ã€è¿è¡Œç¤ºä¾‹

// è¾…åŠ©å‡½æ•°ï¼šæ ¼å¼åŒ–è¾“å‡ºæ¶ˆæ¯
const logMessages = (messages: BaseMessage[]) => {
    messages.forEach((msg) => {
        console.log(`ã€${msg.getType()}ã€‘`, msg.content);
    })
}

async function runDemo() {
    console.log("\n%c â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•", "color:#33a5ff");
    console.log("%c   ğŸ› ï¸  LangGraph å·¥å…·è°ƒç”¨æ¼”ç¤º", "color:#33a5ff; font-weight:bold");
    console.log("%c â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n", "color:#33a5ff");

    console.log("ğŸ“ æµ‹è¯•1: æŸ¥è¯¢å¤©æ°”")
    const res1 = await toolsGraph.invoke({ messages: [new HumanMessage("åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·")] })
    logMessages(res1.messages)

    console.log("\nğŸ“ æµ‹è¯•2: æ•°å­¦è®¡ç®—")
    const res2 = await toolsGraph.invoke({ messages: [new HumanMessage("å¸®æˆ‘è®¡ç®— 123 * 456")] })
    logMessages(res2.messages)
}

if (require.main === module) {
    runDemo()
}



